name: PCA
inputs:
  - {name: input_data_path, type: Directory, description: "Dataset path (CSV, Parquet, or JSONL)"}
  - {name: target_column, type: string, default: "", description: "Optional target column to exclude from PCA"}
  - {name: n_components, type: string, default: "auto", description: "Number of components, ratio, or 'auto'"}
  - {name: auto_variance_threshold, type: string, default: "0.88", description: "Variance threshold for auto mode"}
  - {name: pca_variant, type: string, default: "Standard PCA", description: "PCA variant selection"}
  - {name: random_state, type: Integer, default: "50", description: "Random seed"}
  - {name: output_format, type: string, default: "csv", description: "csv | json | parquet"}
outputs:
  - {name: training_results_out, type: Dataset, description: "PCA-transformed dataset"}
  - {name: pca_pickle_file, type: Model, description: "Cloudpickle PCA model file"}
  - {name: pca_metadata_file, type: File, description: "Metadata JSON file"}

implementation:
  container:
    image: python:3.9
    command:
      - python3
      - -u
      - -c
      - |
        import argparse, logging, os, pickle, pandas as pd, numpy as np, requests
        from io import BytesIO
        from sklearn.decomposition import PCA, KernelPCA, IncrementalPCA, SparsePCA, FactorAnalysis, FastICA
        import cloudpickle, gzip, json

        parser = argparse.ArgumentParser()
        parser.add_argument('--input_data_path', required=True)
        parser.add_argument('--target_column', default="")
        parser.add_argument('--n_components', default="0.95")
        parser.add_argument('--auto_variance_threshold', default="0.95")
        parser.add_argument('--pca_variant', default="Standard PCA")
        parser.add_argument('--random_state', type=int, default=42)
        parser.add_argument('--output_format', default="csv")
        parser.add_argument('--training_results_out', required=True)
        parser.add_argument('--pca_pickle_file', required=True)
        parser.add_argument('--pca_metadata_file', required=True)
        args = parser.parse_args()

        logging.basicConfig(level=logging.INFO)
        log = logging.getLogger("raw_pca")

        def load(path):
            if path.startswith(("http://", "https://")):
                r = requests.get(path, timeout=60)
                r.raise_for_status()
                b = BytesIO(r.content)
                if path.endswith(".csv"): return pd.read_csv(b)
                if path.endswith(".parquet"): return pd.read_parquet(b)
                if path.endswith(".json") or path.endswith(".jsonl"): return pd.read_json(b, lines=True)
                if path.endswith(".pkl"): return pickle.load(b)
                raise SystemExit("Unsupported remote format.")
            else:
                if path.endswith(".csv"): return pd.read_csv(path)
                if path.endswith(".parquet"): return pd.read_parquet(path)
                if path.endswith(".json") or path.endswith(".jsonl"): return pd.read_json(path, lines=True)
                if path.endswith(".pkl"): return pickle.load(open(path, "rb"))
                raise SystemExit("Unsupported local format.")

        df = load(args.input_data_path)
        log.info(f"Raw dataset loaded with shape: {df.shape}")

        if args.target_column and args.target_column in df.columns:
            y = df[args.target_column]
            X = df.drop(columns=[args.target_column])
        else:
            X, y = df, None

        # No preprocessing. Direct PCA on raw data.
        X_raw = X.values

        # n_components parsing
        use_auto = args.n_components.lower() == "auto"

        if use_auto:
            full_pca = PCA(random_state=args.random_state)
            full_pca.fit(X_raw)
            var = np.cumsum(full_pca.explained_variance_ratio_)
            threshold = float(args.auto_variance_threshold)
            n_comp = np.argmax(var >= threshold) + 1
        else:
            n_comp_val = float(args.n_components)
            n_comp = int(n_comp_val) if n_comp_val.is_integer() else n_comp_val

        variant = args.pca_variant.strip()

        if variant == "Standard PCA":
            pca = PCA(n_components=n_comp, random_state=args.random_state)
        elif variant == "Kernel PCA":
            pca = KernelPCA(n_components=int(n_comp), kernel='rbf')
        elif variant == "Incremental PCA":
            pca = IncrementalPCA(n_components=int(n_comp))
        elif variant == "Randomized PCA":
            pca = PCA(n_components=int(n_comp), svd_solver='randomized', random_state=args.random_state)
        elif variant == "Sparse PCA":
            pca = SparsePCA(n_components=int(n_comp), random_state=args.random_state)
        elif variant == "Factor Analysis (FA)":
            pca = FactorAnalysis(n_components=int(n_comp), random_state=args.random_state)
        elif variant == "Independent Component Analysis (ICA)":
            pca = FastICA(n_components=int(n_comp), random_state=args.random_state)
        else:
            raise SystemExit(f"Unknown variant: {variant}")

        X_pca = pca.fit_transform(X_raw)
        df_pca = pd.DataFrame(X_pca, columns=[f"Component_{i+1}" for i in range(X_pca.shape[1])])
        if y is not None:
            df_pca[args.target_column] = y.values

        fmt = args.output_format.lower()
        out_path = args.training_results_out

        if fmt == "csv":
            df_pca.to_csv(out_path, index=False)
        elif fmt == "json":
            df_pca.to_json(out_path, orient="records", lines=True)
        else:
            df_pca.to_parquet(out_path, index=False)

        with gzip.open(args.pca_pickle_file, "wb") as f:
            cloudpickle.dump(pca, f)

        metadata = {
            "variant": variant,
            "n_components": X_pca.shape[1],
            "original_features": X.shape[1],
            "auto_selected": use_auto,
            "feature_names": list(X.columns),
            "model_file": args.pca_pickle_file
        }

        with open(args.pca_metadata_file, "w") as f:
            json.dump(metadata, f, indent=2)

    args:
      - --input_data_path
      - {inputValue: input_data_path}
      - --target_column
      - {inputValue: target_column}
      - --n_components
      - {inputValue: n_components}
      - --auto_variance_threshold
      - {inputValue: auto_variance_threshold}
      - --pca_variant
      - {inputValue: pca_variant}
      - --random_state
      - {inputValue: random_state}
      - --output_format
      - {inputValue: output_format}
      - --training_results_out
      - {outputPath: training_results_out}
      - --pca_pickle_file
      - {outputPath: pca_pickle_file}
      - --pca_metadata_file
      - {outputPath: pca_metadata_file}
