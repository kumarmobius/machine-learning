name: Load Data into Pandas
description: |
  Loads a local dataset file (CSV, JSON, Excel, TSV, or Parquet)
  into a pandas DataFrame, automatically detects file format,
  and saves processed, preview, schema, and row count outputs.
inputs:
  - {name: in_file, type: Data, description: "Path to local file to load"}
  - {name: preview_rows, type: Integer, description: "Number of rows for preview JSON", default: "20"}
outputs:
  - {name: processed_file, type: Data, description: "Processed data file (Parquet format)"}
  - {name: preview_file, type: Data, description: "Preview of top N rows (JSON)"}
  - {name: schema_file, type: Data, description: "JSON schema of columns and dtypes"}
  - {name: row_count, type: Integer, description: "Row count of dataset"}
implementation:
  container:
    image: python:3.10
    command:
      - python3
      - -u
      - -c
      - |
        import pandas as pd, os, json, sys, argparse

        parser = argparse.ArgumentParser()
        parser.add_argument('--in_file', type=str, required=True)
        parser.add_argument('--preview_rows', type=int, default=20)
        parser.add_argument('--processed_file', type=str, required=True)
        parser.add_argument('--preview_file', type=str, required=True)
        parser.add_argument('--schema_file', type=str, required=True)
        parser.add_argument('--row_count', type=str, required=True)
        args = parser.parse_args()

        os.makedirs(os.path.dirname(args.processed_file), exist_ok=True)

        path = args.in_file
        ext = os.path.splitext(path)[1].lower()
        print(f"Loading file: {path} (detected type: {ext})")

        if ext in ['.csv', '.tsv']:
            sep = '\t' if ext == '.tsv' else ','
            df = pd.read_csv(path, sep=sep)
        elif ext in ['.json']:
            df = pd.read_json(path)
        elif ext in ['.xls', '.xlsx']:
            df = pd.read_excel(path)
        elif ext in ['.parquet']:
            df = pd.read_parquet(path)
        else:
            print(f" Unsupported file type: {ext}")
            sys.exit(1)

        # Save processed file
        df.to_parquet(args.processed_file, index=False)

        # Save preview
        df.head(args.preview_rows).to_json(args.preview_file, orient='records', indent=2)

        # Save schema
        schema = {col: str(dtype) for col, dtype in df.dtypes.items()}
        json.dump(schema, open(args.schema_file, 'w'), indent=2)

        # Save row count
        open(args.row_count, 'w').write(str(len(df)))

        print(f"Data loaded successfully:")
        print(f"Processed: {args.processed_file}")
        print(f"Preview: {args.preview_file}")
        print(f"Schema: {args.schema_file}")
        print(f"Row count: {len(df)}")

    args:
      - --processed_file
      - {outputPath: processed_file}
      - --preview_file
      - {outputPath: preview_file}
      - --schema_file
      - {outputPath: schema_file}
      - --row_count
      - {outputPath: row_count}
