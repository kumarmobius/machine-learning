name: Artifacts downloader from CDN v2
inputs:
  - {name: preprocessor_cdn, type: String, optional: true, default: ""}
  - {name: feature_selector_cdn, type: String, optional: true, default: ""}
  - {name: pca_cdn, type: String, optional: true, default: ""}
  - {name: model_pickle_cdn, type: String, optional: true, default: ""}
  - {name: bearer_token, type: string, optional: true, default: ""}

outputs:
  - {name: preprocessor_local, type: Data}
  - {name: feature_selector_local, type: Data}
  - {name: pca_local, type: Data}
  - {name: model_pickle_local, type: Model}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:vtests3
    command:
      - python3
      - -u
      - -c
      - |
        import argparse, os, sys, tempfile, json, shutil, zipfile, logging
        import numpy as np
        import requests
        from requests.adapters import HTTPAdapter
        try:
            from urllib3.util import Retry
        except Exception:
            from urllib3 import Retry

        parser = argparse.ArgumentParser()
        parser.add_argument('--preprocessor_cdn', default="")
        parser.add_argument('--feature_selector_cdn', default="")
        parser.add_argument('--pca_cdn', default="")
        parser.add_argument('--model_pickle_cdn', default="")
        parser.add_argument('--bearer_token', default="")
        parser.add_argument('--preprocessor_local', required=True)
        parser.add_argument('--feature_selector_local', required=True)
        parser.add_argument('--pca_local', required=True)
        parser.add_argument('--model_pickle_local', required=True)
        args = parser.parse_args()

        logging.basicConfig(stream=sys.stdout, level=logging.INFO)
        logger = logging.getLogger("artifacts_downloader")

        session = requests.Session()
        retry = Retry(total=5, backoff_factor=1, status_forcelist=[500,502,503,504])
        session.mount("http://", HTTPAdapter(max_retries=retry))
        session.mount("https://", HTTPAdapter(max_retries=retry))

        headers = {}
        if args.bearer_token and os.path.exists(args.bearer_token):
            with open(args.bearer_token, "r") as f:
                token = f.read().strip()
                if token:
                    headers["Authorization"] = f"Bearer {token}"

        def candidate_urls(url):
            if "$$$_" in url:
                return [url, url.replace("$$$_", "$$_")]
            return [url]

        def download_with_fallback(url):
            last_err = None
            for u in candidate_urls(url):
                try:
                    logger.info("Trying download: %s", u)
                    r = session.get(u, headers=headers, timeout=60)
                    r.raise_for_status()
                    fd, tmp = tempfile.mkstemp()
                    os.close(fd)
                    with open(tmp, "wb") as f:
                        f.write(r.content)
                    return tmp
                except Exception as e:
                    logger.warning("Download failed for %s", u)
                    last_err = e
            raise last_err

        def place_artifact(tmp_file, out_path):
            try:
                with zipfile.ZipFile(tmp_file):
                    is_zip = True
            except zipfile.BadZipFile:
                is_zip = False

            if is_zip:
                os.makedirs(out_path, exist_ok=True)
                with zipfile.ZipFile(tmp_file, "r") as z:
                    z.extractall(out_path)
                os.remove(tmp_file)
                return out_path
            else:
                os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
                shutil.move(tmp_file, out_path)
                return out_path

        def write_output(out_path, val):
            with open(out_path, "w") as f:
                f.write("" if val is None else str(val))
            with open(out_path + ".meta.json", "w") as f:
                json.dump({"artifact_local": val}, f)

        def fetch(url, out_path):
            if not url.strip():
                write_output(out_path, None)
                return None
            try:
                tmp = download_with_fallback(url)
                placed = place_artifact(tmp, out_path)
                write_output(out_path, placed)
                return placed
            except Exception as e:
                logger.exception("Final failure downloading %s", url)
                write_output(out_path, None)
                return None

        pre = fetch(args.preprocessor_cdn, args.preprocessor_local)
        feat = fetch(args.feature_selector_cdn, args.feature_selector_local)
        pca = fetch(args.pca_cdn, args.pca_local)
        model = fetch(args.model_pickle_cdn, args.model_pickle_local)

        logger.info("Done. pre=%s feat=%s pca=%s model=%s", pre, feat, pca, model)

    args:
      - --preprocessor_cdn
      - {inputValue: preprocessor_cdn}
      - --feature_selector_cdn
      - {inputValue: feature_selector_cdn}
      - --pca_cdn
      - {inputValue: pca_cdn}
      - --model_pickle_cdn
      - {inputValue: model_pickle_cdn}
      - --bearer_token
      - {inputPath: bearer_token}
      - --preprocessor_local
      - {outputPath: preprocessor_local}
      - --feature_selector_local
      - {outputPath: feature_selector_local}
      - --pca_local
      - {outputPath: pca_local}
      - --model_pickle_local
      - {outputPath: model_pickle_local}
