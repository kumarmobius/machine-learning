name: Update Schema Row v8
inputs:
  - { name: schema_id, type: String }
  - { name: update_data_json, type: String }
  - { name: mapping_json, type: String }
  - { name: model_id, type: String }
  - { name: execution_id, type: Integer }
  - { name: tenant_id, type: string }
  - { name: project_id, type: String }
  - { name: architecture_type, type: String }
  - { name: multiple_rows_json, type: String }
  - { name: bearer_auth_token, type: string }
  - { name: domain, type: String }

implementation:
  container:
    image: python:3.9-slim
    command:
      - sh
      - -c
      - |
        pip install --no-cache-dir requests urllib3 && exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import json
        import argparse
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        import os
        import sys

        parser = argparse.ArgumentParser()
        parser.add_argument('--schema_id', type=str, required=True)
        parser.add_argument('--update_data_json', type=str, required=True)
        parser.add_argument('--mapping_json', type=str, required=True)
        parser.add_argument('--model_id', type=str, required=True)
        parser.add_argument('--execution_id', type=int, required=True)
        parser.add_argument('--tenant_id', type=str, required=True)
        parser.add_argument('--project_id', type=str, required=True)
        parser.add_argument('--architecture_type', type=str, required=True)
        parser.add_argument('--multiple_rows_json', type=str, required=True)
        parser.add_argument('--bearer_auth_token', type=str, required=True)
        parser.add_argument('--domain', type=str, required=True)

        args = parser.parse_args()

        # Helper function to check if value should be omitted from payload
        def should_skip_field(val):
            return str(val).strip() == "-1"

        # Keep values as provided
        model_id = args.model_id
        execution_id = args.execution_id
        project_id_val = args.project_id

        # READ FILES (support passing file path for tenant_id and bearer token)
        def read_file_if_path(path):
            if path and not should_skip_field(path):
                if os.path.exists(path):
                    with open(path, 'r') as f:
                        return f.read().strip()
                else:
                    print(f"Warning: file '{path}' not found", file=sys.stderr)
                    return ''
            return ''

        bearer_auth_token = read_file_if_path(args.bearer_auth_token)
        tenant_id_file_value = read_file_if_path(args.tenant_id)

        # Parse JSON inputs (tolerate '-1' sentinel)
        try:
            update_data = json.loads(args.update_data_json) if args.update_data_json and not should_skip_field(args.update_data_json) else {}
            mapping = json.loads(args.mapping_json) if args.mapping_json and not should_skip_field(args.mapping_json) else {}
        except Exception as e:
            print("Invalid JSON for update_data_json or mapping_json:", e, file=sys.stderr)
            sys.exit(1)

        def coerce_if_needed(key, value):
            return value

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {bearer_auth_token}" if bearer_auth_token else ""
        }

        retry_strategy = Retry(
            total=3,
            status_forcelist=[408, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "PUT", "POST", "PATCH", "DELETE", "OPTIONS"],
            backoff_factor=1
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        http = requests.Session()
        http.mount("http://", adapter)
        http.mount("https://", adapter)

        # MULTIPLE ROWS PATH
        if not should_skip_field(args.multiple_rows_json):
            try:
                rows = json.loads(args.multiple_rows_json)
                if not isinstance(rows, list):
                    raise Exception("multiple_rows_json must be a JSON list")
            except Exception as e:
                print("Error in multiple_rows_json:", e, file=sys.stderr)
                sys.exit(1)

            processed_rows = []
            for idx, row in enumerate(rows):
                # Inject tenant_id if provided and not -1
                if not should_skip_field(args.tenant_id) and tenant_id_file_value:
                    row["tenant_id"] = tenant_id_file_value
                
                # Inject projectId if provided and not -1
                if not should_skip_field(args.project_id):
                    row["projectId"] = project_id_val
                
                # Inject architecture_type if provided and not -1
                if not should_skip_field(args.architecture_type):
                    row["architecture_type"] = args.architecture_type
                
                # Inject model_id if provided and not -1 and not already present
                if not should_skip_field(args.model_id) and "model_id" not in row:
                    row["model_id"] = model_id
                
                # Ensure execution_id exists on each row (integer)
                if "execution_id" not in row:
                    row["execution_id"] = int(execution_id)
                
                processed_rows.append(row)

            # Post all processed rows
            if processed_rows:
                create_url = f"{args.domain.rstrip('/')}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
                payload = {"data": processed_rows}
                resp = http.post(create_url, headers=headers, data=json.dumps(payload))
                print(resp.text)
                resp.raise_for_status()
                print(f"SUCCESS: Posted {len(processed_rows)} rows")
            else:
                print("INFO: No rows to process.")
            
            sys.exit(0)

        # SINGLE ROW – CHECK EXISTENCE
        check_url = f"{args.domain.rstrip('/')}/pi-entity-instances-service/v3.0/schemas/{args.schema_id}/instances/list"
        check_payload = {
            "dbType": "TIDB",
            "ownedOnly": True,
            "filter": {"execution_id": execution_id}
        }

        resp = http.post(check_url, headers=headers, data=json.dumps(check_payload))
        resp.raise_for_status()
        data = resp.json()

        # If row exists → UPDATE
        if data.get("content"):
            patch_list = []
            for column, keys in mapping.items():
                if isinstance(keys, list):
                    obj = {}
                    for k in keys:
                        if k in update_data:
                            obj[k] = coerce_if_needed(k, update_data[k])
                    if obj:
                        patch_list.append({"operation": "REPLACE", "path": column, "value": obj})
                else:
                    if keys in update_data:
                        patch_list.append({
                            "operation": "REPLACE",
                            "path": column,
                            "value": coerce_if_needed(keys, update_data[keys])
                        })

            update_url = f"{args.domain.rstrip('/')}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
            update_payload = {
                "dbType": "TIDB",
                "conditionalFilter": {
                    "conditions": [
                        {"field": "execution_id", "operator": "EQUAL", "value": execution_id}
                    ]
                },
                "partialUpdateRequests": [{"patch": patch_list}]
            }

            resp = http.patch(update_url, headers=headers, data=json.dumps(update_payload))
            print(resp.text)
            resp.raise_for_status()
            print("SUCCESS: Updated existing row")

        else:
            # CREATE NEW ROW
            creation = {}
            for column, keys in mapping.items():
                if isinstance(keys, list):
                    obj = {}
                    for k in keys:
                        if k in update_data:
                            obj[k] = coerce_if_needed(k, update_data[k])
                    if obj:
                        creation[column] = obj
                else:
                    if keys in update_data:
                        creation[column] = coerce_if_needed(keys, update_data[keys])

            # Always add execution_id
            creation["execution_id"] = int(execution_id)
            
            # Conditionally add fields only if NOT -1
            if not should_skip_field(args.model_id):
                creation["model_id"] = model_id
            
            if not should_skip_field(args.tenant_id) and tenant_id_file_value:
                creation["tenant_id"] = tenant_id_file_value
            
            if not should_skip_field(args.project_id):
                creation["projectId"] = project_id_val
            
            if not should_skip_field(args.architecture_type):
                creation["architecture_type"] = args.architecture_type

            create_url = f"{args.domain.rstrip('/')}/pi-entity-instances-service/v2.0/schemas/{args.schema_id}/instances"
            payload = {"data": [creation]}

            resp = http.post(create_url, headers=headers, data=json.dumps(payload))
            print(resp.text)
            resp.raise_for_status()
            print("SUCCESS: Created new row")

    args:
      - --schema_id
      - {inputValue: schema_id}
      - --update_data_json
      - {inputValue: update_data_json}
      - --mapping_json
      - {inputValue: mapping_json}
      - --model_id
      - {inputValue: model_id}
      - --execution_id
      - {inputValue: execution_id}
      - --tenant_id
      - {inputPath: tenant_id}
      - --project_id
      - {inputValue: project_id}
      - --architecture_type
      - {inputValue: architecture_type}
      - --multiple_rows_json
      - {inputValue: multiple_rows_json}
      - --bearer_auth_token
      - {inputPath: bearer_auth_token}
      - --domain
      - {inputValue: domain}
