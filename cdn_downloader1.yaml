name: ML Artifacts Downloader v7
description: Downloads ML artifacts from CDN URLs and saves them locally

inputs:
  - {name: preprocessor_metadata_cdn, type: String, description: "CDN URL to download preprocessor metadata artifact", optional: true, default: ""}
  - {name: cleaning_metadata_cdn, type: String, description: "CDN URL to download cleaning metadata artifact", optional: true, default: ""}
  - {name: feature_selector_cdn, type: String, description: "CDN URL to download feature selector artifact", optional: true, default: ""}
  - {name: pca_cdn, type: String, description: "CDN URL to download PCA artifact", optional: true, default: ""}
  - {name: preprocessor_cdn, type: String, description: "CDN URL to download preprocessor artifact", optional: true, default: ""}
  - {name: x_train_cdn, type: String, description: "CDN URL to download training features dataset", optional: true, default: ""}
  - {name: y_train_cdn, type: String, description: "CDN URL to download training labels dataset", optional: true, default: ""}
  - {name: test_data_cdn, type: String, description: "CDN URL to download test dataset", optional: true, default: ""}
  - {name: bearer_token, type: string, description: "Optional path to file containing bearer token for authenticated downloads", optional: true, default: ""}

outputs:
  - {name: preprocessor_metadata_local, type: Data, description: "Local path for downloaded preprocessor metadata"}
  - {name: cleaning_metadata_local, type: Data, description: "Local path for downloaded cleaning metadata"}
  - {name: feature_selector_local, type: Data, description: "Local path for downloaded feature selector"}
  - {name: pca_local, type: Data, description: "Local path for downloaded PCA"}
  - {name: preprocessor_local, type: Data, description: "Local path for downloaded preprocessor"}
  - {name: x_train_local, type: Dataset, description: "Local path for downloaded x_train dataset"}
  - {name: y_train_local, type: Dataset, description: "Local path for downloaded y_train dataset"}
  - {name: test_data_local, type: Dataset, description: "Local path for downloaded test_data dataset"}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:vtest4
    command:
      - python3
      - -u
      - -c
      - |
        import argparse, os, sys, tempfile, shutil, zipfile, logging
        import requests
        from requests.adapters import HTTPAdapter
        try:
            from urllib3.util import Retry
        except Exception:
            from urllib3 import Retry

        parser = argparse.ArgumentParser()
        parser.add_argument('--preprocessor_metadata_cdn', type=str, default="")
        parser.add_argument('--cleaning_metadata_cdn', type=str, default="")
        parser.add_argument('--feature_selector_cdn', type=str, default="")
        parser.add_argument('--pca_cdn', type=str, default="")
        parser.add_argument('--preprocessor_cdn', type=str, default="")
        parser.add_argument('--x_train_cdn', type=str, default="")
        parser.add_argument('--y_train_cdn', type=str, default="")
        parser.add_argument('--test_data_cdn', type=str, default="")
        parser.add_argument('--bearer_token', type=str, default="")

        parser.add_argument('--preprocessor_metadata_local', type=str, required=True)
        parser.add_argument('--cleaning_metadata_local', type=str, required=True)
        parser.add_argument('--feature_selector_local', type=str, required=True)
        parser.add_argument('--pca_local', type=str, required=True)
        parser.add_argument('--preprocessor_local', type=str, required=True)
        parser.add_argument('--x_train_local', type=str, required=True)
        parser.add_argument('--y_train_local', type=str, required=True)
        parser.add_argument('--test_data_local', type=str, required=True)

        args = parser.parse_args()

        logging.basicConfig(
            stream=sys.stdout,
            level=logging.INFO,
            format="%(asctime)s %(levelname)s %(message)s"
        )
        logger = logging.getLogger("ml_artifacts_downloader")

        session = requests.Session()
        try:
            retry_strategy = Retry(
                total=3,
                backoff_factor=1,
                status_forcelist=[500, 502, 503, 504],
                allowed_methods=frozenset(["GET", "HEAD"])
            )
        except TypeError:
            retry_strategy = Retry(
                total=3,
                backoff_factor=1,
                status_forcelist=[500, 502, 503, 504],
                method_whitelist=frozenset(["GET", "HEAD"])
            )

        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        headers = {}
        if args.bearer_token and os.path.exists(args.bearer_token):
            with open(args.bearer_token, "r", encoding="utf-8") as f:
                token = f.read().strip()
                if token:
                    headers["Authorization"] = f"Bearer {token}"

        def download_file(url):
            logger.info("Downloading: %s", url)
            r = session.get(url, headers=headers, timeout=120)
            r.raise_for_status()
            fd, tmp = tempfile.mkstemp(suffix=".download")
            os.close(fd)
            with open(tmp, "wb") as fh:
                fh.write(r.content)
            return tmp

        def place_artifact(tmp_file, out_path):
            try:
                with zipfile.ZipFile(tmp_file, "r") as z:
                    os.makedirs(out_path, exist_ok=True)
                    z.extractall(out_path)
                    os.remove(tmp_file)
                    return out_path
            except zipfile.BadZipFile:
                os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
                shutil.move(tmp_file, out_path)
                return out_path

        def fetch_artifact(url, out_path):
            if not url or not url.strip():
                os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
                with open(out_path, "w") as fh:
                    fh.write("")
                return None
            tmp = download_file(url)
            return place_artifact(tmp, out_path)

        fetch_artifact(args.preprocessor_metadata_cdn, args.preprocessor_metadata_local)
        fetch_artifact(args.cleaning_metadata_cdn, args.cleaning_metadata_local)
        fetch_artifact(args.feature_selector_cdn, args.feature_selector_local)
        fetch_artifact(args.pca_cdn, args.pca_local)
        fetch_artifact(args.preprocessor_cdn, args.preprocessor_local)
        fetch_artifact(args.x_train_cdn, args.x_train_local)
        fetch_artifact(args.y_train_cdn, args.y_train_local)
        fetch_artifact(args.test_data_cdn, args.test_data_local)

        logger.info("All artifacts downloaded successfully")

    args:
      - --preprocessor_metadata_cdn
      - {inputValue: preprocessor_metadata_cdn}
      - --cleaning_metadata_cdn
      - {inputValue: cleaning_metadata_cdn}
      - --feature_selector_cdn
      - {inputValue: feature_selector_cdn}
      - --pca_cdn
      - {inputValue: pca_cdn}
      - --preprocessor_cdn
      - {inputValue: preprocessor_cdn}
      - --x_train_cdn
      - {inputValue: x_train_cdn}
      - --y_train_cdn
      - {inputValue: y_train_cdn}
      - --test_data_cdn
      - {inputValue: test_data_cdn}
      - --bearer_token
      - {inputPath: bearer_token}
      - --preprocessor_metadata_local
      - {outputPath: preprocessor_metadata_local}
      - --cleaning_metadata_local
      - {outputPath: cleaning_metadata_local}
      - --feature_selector_local
      - {outputPath: feature_selector_local}
      - --pca_local
      - {outputPath: pca_local}
      - --preprocessor_local
      - {outputPath: preprocessor_local}
      - --x_train_local
      - {outputPath: x_train_local}
      - --y
