name: Feature Selection v2
inputs:
  - {name: engineered_X, type: Dataset, description: "Features after Brick 2"}
  - {name: train_y, type: Dataset, description: "Targets from Brick 2"}
  - {name: model_type, type: String, description: "classification or regression", optional: false}
  - {name: enable_feature_selection, type: String, description: "true/false switch", optional: false}

outputs:
  - {name: selected_X, type: Dataset, description: "Final selected features", default: "selected_X.parquet"}
  - {name: selected_y, type: Dataset, description: "Final selected targets", default: "selected_y.parquet"}
  - {name: feature_selector, type: Data, description: "Pickled FeatureSelector", default: "feature_selector.pkl.gz"}
  - {name: fs_metadata, type: Data, description: "Feature selection metadata", default: "fs_metadata.json"}

implementation:
  container:
    image: kumar2004/ml-base:v1
    command:
      - python3
      - -u
      - -c
      - |
        import argparse, os, sys, json, traceback, gzip, math
        import pandas as pd, numpy as np
        from sklearn.feature_selection import VarianceThreshold, mutual_info_classif, mutual_info_regression
        from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor
        from sklearn.inspection import permutation_importance
        import cloudpickle

        def ensure_dir_for(p):
            d = os.path.dirname(p)
            if d and not os.path.exists(d):
                os.makedirs(d, exist_ok=True)

        # ===========================================================
        #   FEATURE SELECTOR (Option A: NZV + Corr + MI + MRMR + PI)
        # ===========================================================
        class FeatureSelector:
            _VAR_THRESH = 1e-5
            _CORR_THRESH = 0.95
            _PI_REPEATS = 5
            _RANDOM_STATE = 42

            def __init__(self, task):
                self.task = task
                self.selected_features = []
                self._filter_keep_ = []
                self._mi_scores_ = pd.Series(dtype=float)
                self._pi_importance_ = pd.Series(dtype=float)

            # -----------------------------
            def _auto_k(self, p, n_samples=None):
                if n_samples is None:
                    return max(10, min(int(math.sqrt(p) * 3.0), p))
                if n_samples < 500:
                    base_k = max(10, min(int(math.sqrt(p) * 1.5), int(p * 0.6)))
                elif n_samples < 5000:
                    base_k = max(10, min(int(math.sqrt(p) * 3), int(p * 0.7)))
                else:
                    base_k = max(10, min(int(math.sqrt(p) * 4), int(p * 0.8)))
                return min(base_k, max(10, n_samples // 5))

            # -----------------------------
            @staticmethod
            def _nzv_keep(X, thr):
                if X.shape[1] == 0: return []
                vt = VarianceThreshold(thr)
                vt.fit(X.values)
                return list(X.columns[vt.get_support()])

            # -----------------------------
            @staticmethod
            def _corr_prune_keep(X, thr):
                cols = list(X.columns)
                if len(cols) <= 1: return cols
                corr = X.corr(method="spearman").abs()
                keep = set(cols)
                while True:
                    sub = corr.loc[list(keep), list(keep)]
                    np.fill_diagonal(sub.values, 0.0)
                    mv = sub.values.max()
                    if not np.isfinite(mv) or mv < thr: break
                    i, j = np.unravel_index(np.argmax(sub.values), sub.shape)
                    a, b = sub.index[i], sub.columns[j]
                    drop = a if sub[a].mean() >= sub[b].mean() else b
                    keep.remove(drop)
                return list(keep)

            # -----------------------------
            def _mi(self, X, y):
                if self.task == "classification":
                    sc = mutual_info_classif(X.values, y, random_state=self._RANDOM_STATE)
                else:
                    sc = mutual_info_regression(X.values, y, random_state=self._RANDOM_STATE)
                return pd.Series(sc, index=X.columns).fillna(0.0)

            # -----------------------------
            @staticmethod
            def _mrmr_greedy(X, mi, k):
                k = max(1, min(k, X.shape[1]))
                corr = X.corr(method="spearman").abs().fillna(0.0)
                selected, candidates = [], list(X.columns)
                while len(selected) < k and candidates:
                    best, best_score = None, -1e18
                    for c in candidates:
                        rel = float(mi.get(c, 0.0))
                        red = corr.loc[c, selected].mean() if selected else 0.0
                        score = rel - red
                        if score > best_score:
                            best_score, best = score, c
                    selected.append(best)
                    candidates.remove(best)
                return selected

            # -----------------------------
            def _pi_keep(self, X, y):
                if self.task == "classification":
                    est = ExtraTreesClassifier(n_estimators=400, max_features="sqrt",
                                               random_state=self._RANDOM_STATE, n_jobs=-1)
                else:
                    est = ExtraTreesRegressor(n_estimators=400, max_features="sqrt",
                                              random_state=self._RANDOM_STATE, n_jobs=-1)
                est.fit(X, y)
                pi = permutation_importance(est, X, y, n_repeats=self._PI_REPEATS,
                                            random_state=self._RANDOM_STATE, n_jobs=-1)
                imp = pd.Series(pi.importances_mean, index=X.columns).fillna(0.0)
                keep = list(imp[imp > 0].index)
                if not keep:
                    keep = [imp.sort_values(ascending=False).index[0]]
                return keep, imp

            # -----------------------------
            def fit(self, X, y):
                y = np.asarray(y).ravel()

                # 1. NZV
                keep1 = self._nzv_keep(X, self._VAR_THRESH)
                X1 = X[keep1]

                # 2. Corr prune
                keep2 = self._corr_prune_keep(X1, self._CORR_THRESH)
                Xf = X1[keep2]

                # 3. MI
                mi = self._mi(Xf, y)
                self._mi_scores_ = mi
                k = self._auto_k(Xf.shape[1], len(Xf))

                # 4. MRMR
                keep_mrmr = self._mrmr_greedy(Xf, mi, k)
                Xr = Xf[keep_mrmr]

                # 5. Permutation importance
                keep_pi, imp = self._pi_keep(Xr, y)
                self._pi_importance_ = imp
                self.selected_features = keep_pi
                return self

            def transform(self, X):
                return X.reindex(columns=self.selected_features, fill_value=0.0)

            def save(self, p):
                with gzip.open(p, "wb") as f:
                    cloudpickle.dump(self, f)


        parser = argparse.ArgumentParser()
        parser.add_argument("--engineered_X", required=True)
        parser.add_argument("--train_y", required=True)
        parser.add_argument("--model_type", required=True)
        parser.add_argument("--enable_feature_selection", required=True)
        parser.add_argument("--selected_X", required=True)
        parser.add_argument("--selected_y", required=True)
        parser.add_argument("--feature_selector", required=True)
        parser.add_argument("--fs_metadata", required=True)
        args = parser.parse_args()

        try:
            X = pd.read_parquet(args.engineered_X)
            y = pd.read_parquet(args.train_y)

            if isinstance(y, pd.DataFrame):
                y_fs = y.iloc[:, 0]
            else:
                y_fs = y

            enable_fs = args.enable_feature_selection.lower() in ("1", "true", "yes", "y")
            task = args.model_type.lower()

            if not enable_fs:
                X.to_parquet(args.selected_X, index=False)
                y.to_parquet(args.selected_y, index=False)

                dummy = type("Dummy", (), {
                    "selected_features": list(X.columns),
                    "transform": lambda self, X: X
                })()

                with gzip.open(args.feature_selector, "wb") as f:
                    cloudpickle.dump(dummy, f)

                meta = {
                    "enabled": False,
                    "selected_features": list(X.columns),
                    "reason": "Feature selection disabled",
                    "input_shape": list(X.shape)
                }
                with open(args.fs_metadata, "w") as f:
                    json.dump(meta, f, indent=2)
                sys.exit(0)

            fs = FeatureSelector(task)
            fs.fit(X, y_fs)

            Xs = fs.transform(X)

            Xs.to_parquet(args.selected_X, index=False)
            y.to_parquet(args.selected_y, index=False)
            fs.save(args.feature_selector)

            meta = {
                "enabled": True,
                "input_shape": list(X.shape),
                "output_shape": list(Xs.shape),
                "n_selected": len(fs.selected_features),
                "selected_features": fs.selected_features,
            }
            with open(args.fs_metadata, "w") as f:
                json.dump(meta, f, indent=2)

        except Exception as e:
            print("ERROR:", str(e), file=sys.stderr)
            traceback.print_exc()
            sys.exit(1)

  args:
    - --engineered_X
    - {inputPath: engineered_X}
    - --train_y
    - {inputPath: train_y}
    - --model_type
    - {inputValue: model_type}
    - --enable_feature_selection
    - {inputValue: enable_feature_selection}
    - --selected_X
    - {outputPath: selected_X}
    - --selected_y
    - {outputPath: selected_y}
    - --feature_selector
    - {outputPath: feature_selector}
    - --fs_metadata
    - {outputPath: fs_metadata}
