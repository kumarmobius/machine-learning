name: Train Logistic or Linear v3
description: |
  Reads X and y from parquet, trains LogisticRegression for classification or LinearRegression for regression.
  Supports class imbalance when enbalance=true for classification.
  Uses optional preprocess_metadata to map target labels consistently.
  Saves trained model and training metrics.

inputs:
  - {name: X_data, type: Data, description: "Parquet file for features (DataFrame)"}
  - {name: y_data, type: Data, description: "Parquet file for target (Series or single-column DataFrame)"}
  - {name: model_type, type: String, description: "classification or regression", optional: true, default: "classification"}
  - {name: enbalance, type: String, description: "true/false for class imbalance handling (classification only)", optional: true, default: "true"}
  - {name: target_column, type: String, description: "Optional. Column name inside y parquet if it has multiple columns", optional: true, default: ""}
  - {name: preprocess_metadata, type: Data, description: "Optional metadata from preprocessing to map target labels", optional: true}
  - {name: max_iter, type: Integer, description: "LogisticRegression max_iter", optional: true, default: "1000"}
  - {name: C, type: Float, description: "Inverse of regularization strength for LogisticRegression", optional: true, default: "1.0"}
  - {name: penalty, type: String, description: "LogisticRegression regularization: l2 or none", optional: true, default: "l2"}
  - {name: solver, type: String, description: "LogisticRegression solver: lbfgs or saga or newton-cg or liblinear", optional: true, default: "lbfgs"}

outputs:
  - {name: model_pickle, type: Data, description: "Pickled trained model (.pkl)"}
  - {name: metrics_json, type: Data, description: "Training metrics JSON"}

implementation:
  container:
    image: kumar2004/ml-base:v1
    command:
      - python3
      - -u
      - -c
      - |
        import argparse, os, sys, json, traceback
        import pandas as pd, numpy as np
        import joblib

        from sklearn.linear_model import LogisticRegression, LinearRegression
        from sklearn.preprocessing import LabelEncoder
        from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error

        def ensure_dir_for(p):
            d = os.path.dirname(p)
            if d and not os.path.exists(d):
                os.makedirs(d, exist_ok=True)

        def bool_from_str(s):
            return str(s).strip().lower() in ("1","true","t","yes","y")

        def load_parquet_df(path):
            return pd.read_parquet(path, engine="auto")

        def try_load_metadata(path):
            if not path or not os.path.exists(path):
                return None
            # Try JSON first
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception:
                pass
            # Try joblib
            try:
                return joblib.load(path)
            except Exception:
                return None

        def extract_target_mapping(meta):
            if not isinstance(meta, dict):
                return None
            # explicit dict mapping
            for key in ("target_mapping","label_map","target_value_map"):
                if isinstance(meta.get(key), dict):
                    return meta[key]
            # list of classes
            classes_lists = None
            for key in ("target_label_encoder_classes","label_encoder_classes","classes","target_classes"):
                if isinstance(meta.get(key), list):
                    classes_lists = meta[key]
                    break
            if classes_lists is not None:
                return {str(v): i for i, v in enumerate(classes_lists)}
            te = meta.get("target_label_encoder")
            if isinstance(te, dict) and isinstance(te.get("classes_"), list):
                return {str(v): i for i, v in enumerate(te["classes_"])}
            return None

        def normalize_key(x):
            if pd.isna(x):
                return None
            return str(x).strip()

        def coerce_class_labels(y_series):
            s = y_series.copy()
            if pd.api.types.is_integer_dtype(s):
                return s, {"mode": "already_integer"}
            s_str = s.astype(str).str.strip().str.lower()
            pos = {"1","true","yes","y","male","m","positive","pos"}
            neg = {"0","false","no","n","female","f","negative","neg"}
            mask_pos = s_str.isin(pos)
            mask_neg = s_str.isin(neg)
            if (mask_pos | mask_neg).mean() >= 0.9:
                mapped = np.where(mask_pos, 1, np.where(mask_neg, 0, np.nan))
                mapped = pd.Series(mapped, index=s.index)
                return mapped.astype("Int64"), {"mode": "binary_map", "pos_set": sorted(list(pos)), "neg_set": sorted(list(neg))}
            le = LabelEncoder()
            enc = le.fit_transform(s.astype(str))
            return pd.Series(enc, index=s.index, dtype="int64"), {"mode": "label_encoder", "classes_": le.classes_.tolist()}

        def coerce_regression_target(y_series):
            y_num = pd.to_numeric(y_series, errors="coerce")
            return y_num

        ap = argparse.ArgumentParser()
        ap.add_argument('--X_data', type=str, required=True)
        ap.add_argument('--y_data', type=str, required=True)
        ap.add_argument('--model_type', type=str, default="classification")
        ap.add_argument('--enbalance', type=str, default="true")
        ap.add_argument('--target_column', type=str, default="")
        ap.add_argument('--preprocess_metadata', type=str, default="")
        ap.add_argument('--max_iter', type=int, default=1000)
        ap.add_argument('--C', type=float, default=1.0)
        ap.add_argument('--penalty', type=str, default="l2")
        ap.add_argument('--solver', type=str, default="lbfgs")
        ap.add_argument('--model_pickle', type=str, required=True)
        ap.add_argument('--metrics_json', type=str, required=True)
        args = ap.parse_args()

        try:
            print("Loading X from:", args.X_data)
            X = load_parquet_df(args.X_data)
            print("X shape:", X.shape)

            print("Loading y from:", args.y_data)
            y_df = load_parquet_df(args.y_data)

            if isinstance(y_df, pd.DataFrame):
                if y_df.shape[1] == 1 and not args.target_column:
                    y = y_df.iloc[:, 0]
                else:
                    col = args.target_column.strip()
                    if not col:
                        raise ValueError("y parquet has multiple columns. Provide --target_column.")
                    if col not in y_df.columns:
                        raise ValueError("target_column '" + col + "' not found in y parquet. Available: " + str(list(y_df.columns)))
                    y = y_df[col]
            else:
                y = y_df

            print("y length:", len(y))

            if len(X) != len(y):
                common_idx = X.index.intersection(y.index)
                if len(common_idx) > 0:
                    X = X.loc[common_idx].sort_index()
                    y = y.loc[common_idx].sort_index()
                else:
                    m = min(len(X), len(y))
                    print("Warning: X and y length mismatch; aligning by position to", m, "rows.")
                    X = X.reset_index(drop=True).iloc[:m, :]
                    y = y.reset_index(drop=True).iloc[:m]

            for c in X.columns:
                if pd.api.types.is_float_dtype(X[c]) and np.allclose(X[c].dropna(), np.round(X[c].dropna())):
                    try:
                        X[c] = X[c].astype('Int64')
                    except Exception:
                        pass

            task = args.model_type.strip().lower()

            metrics = {"task": task, "samples": int(len(y)), "features": int(X.shape[1])}

            if task == "classification":
                meta = try_load_metadata(args.preprocess_metadata)
                mapping = extract_target_mapping(meta) if meta is not None else None
                if isinstance(mapping, dict):
                    print("Using target mapping from preprocess_metadata")
                    y_map = y.map(lambda v: mapping.get(normalize_key(v), mapping.get(v, None)))
                    if y_map.isna().mean() > 0.1:
                        y_map = y.astype(str).map(lambda v: mapping.get(v, None))
                    y_prepared = y_map.astype("Int64")
                    map_info = {"mode": "metadata_mapping", "keys": list(mapping.keys())[:20]}
                else:
                    y_prepared, map_info = coerce_class_labels(y)

                keep = y_prepared.notna()
                if keep.mean() < 1.0:
                    print("Dropping", int((~keep).sum()), "rows with unmapped target")
                    X = X.loc[keep].reset_index(drop=True)
                    y_prepared = y_prepared.loc[keep].reset_index(drop=True)

                imbalance = bool_from_str(args.enbalance)
                class_weight = "balanced" if imbalance else None

                penalty = args.penalty.strip().lower()
                solver = args.solver.strip().lower()
                if penalty == "none":
                    penalty_arg = "none"
                    if solver not in ("lbfgs","saga","newton-cg"):
                        solver = "lbfgs"
                else:
                    if penalty not in ("l2",):
                        penalty = "l2"
                    penalty_arg = penalty
                    if solver not in ("lbfgs","saga","newton-cg","liblinear"):
                        solver = "lbfgs"

                lr = LogisticRegression(
                    max_iter=int(args.max_iter),
                    multi_class='multinomial',
                    C=float(args.C),
                    penalty=penalty_arg,
                    solver=solver,
                    class_weight=class_weight,
                    n_jobs=-1 if solver in ("saga","liblinear") else None,
                    random_state=42
                )

                lr.fit(X, y_prepared)
                y_hat = lr.predict(X)
                acc = float(accuracy_score(y_prepared, y_hat))

                metrics.update({
                    "accuracy_train": acc,
                    "class_weight": ("balanced" if class_weight == "balanced" else None),
                    "label_info": map_info
                })

                model_obj = lr

            elif task == "regression":
                y_num = pd.to_numeric(y, errors="coerce")
                keep = y_num.notna()
                if keep.mean() < 1.0:
                    print("Dropping", int((~keep).sum()), "rows with non-numeric target")
                    X = X.loc[keep].reset_index(drop=True)
                    y_num = y_num.loc[keep].reset_index(drop=True)

                reg = LinearRegression()
                reg.fit(X, y_num)

                y_hat = reg.predict(X)
                r2 = float(r2_score(y_num, y_hat))
                rmse = float(np.sqrt(mean_squared_error(y_num, y_hat)))
                mae = float(mean_absolute_error(y_num, y_hat))

                metrics.update({
                    "r2_train": r2,
                    "rmse_train": rmse,
                    "mae_train": mae
                })

                model_obj = reg
            else:
                raise ValueError("Unsupported model_type '" + args.model_type + "'. Use 'classification' or 'regression'.")

            ensure_dir_for(args.model_pickle)
            ensure_dir_for(args.metrics_json)
            joblib.dump(model_obj, args.model_pickle)

            with open(args.metrics_json, "w", encoding="utf-8") as f:
                json.dump(metrics, f, indent=2, ensure_ascii=False)

            print("SUCCESS: Trained", task, "model. Metrics:", metrics)
        except Exception as e:
            print("ERROR during training:", e, file=sys.stderr)
            traceback.print_exc()
            sys.exit(1)

    args:
      - --X_data
      - {inputPath: X_data}
      - --y_data
      - {inputPath: y_data}
      - --model_type
      - {inputValue: model_type}
      - --enbalance
      - {inputValue: enbalance}
      - --target_column
      - {inputValue: target_column}
      - --preprocess_metadata
      - {inputPath: preprocess_metadata}
      - --max_iter
      - {inputValue: max_iter}
      - --C
      - {inputValue: C}
      - --penalty
      - {inputValue: penalty}
      - --solver
      - {inputValue: solver}
      - --model_pickle
      - {outputPath: model_pickle}
      - --metrics_json
      - {outputPath: metrics_json}
